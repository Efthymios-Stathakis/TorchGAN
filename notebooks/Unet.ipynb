{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "In this notebook, you're going to implement a U-Net for a biomedical imaging segmentation task. Specifically, you're going to be labeling neurons, so one might call this a neural neural network! ;) \n",
    "\n",
    "Note that this is not a GAN, generative model, or unsupervised learning task. This is a supervised learning task, so there's only one correct answer (like a classifier!) You will see how this component underlies the Generator component of Pix2Pix in the next notebook this week.\n",
    "\n",
    "### Learning Objectives\n",
    "1.   Implement your own U-Net.\n",
    "2.   Observe your U-Net's performance on a challenging segmentation task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.UNET.unet import ContractingBlock, ExpandingBlock, UpsamplingBlock, UNet\n",
    "from models.vis_utils import show_img_batch\n",
    "from models.utils import crop\n",
    "%matplotlib inline\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size        = 64\n",
    "sample             = torch.randn(10, 1, 572, 572)\n",
    "\n",
    "### Contracting network\n",
    "\n",
    "print(\"--------------- Contracting network ---------------\")\n",
    "contracting_block1 = ContractingBlock(1,               hidden_size)\n",
    "contracting_block2 = ContractingBlock(hidden_size * 1, hidden_size * 2)\n",
    "contracting_block3 = ContractingBlock(hidden_size * 2, hidden_size * 4)\n",
    "contracting_block4 = ContractingBlock(hidden_size * 4, hidden_size * 8)\n",
    "contracting_block5 = ContractingBlock(hidden_size * 8, hidden_size * 16)\n",
    "cb1  = contracting_block1(sample)\n",
    "print(\"cb1  shape: \", cb1.shape) \n",
    "cb1_ = nn.MaxPool2d(kernel_size=2, stride=2)(cb1)\n",
    "print(\"cb1_ shape: \", cb1_.shape) \n",
    "cb2 = contracting_block2(cb1_)\n",
    "print(\"cb2  shape: \", cb2.shape) \n",
    "cb2_ = nn.MaxPool2d(kernel_size=2, stride=2)(cb2)\n",
    "print(\"cb2_ shape: \", cb2_.shape) \n",
    "cb3 = contracting_block3(cb2_)\n",
    "print(\"cb3  shape: \", cb3.shape)\n",
    "cb3_ = nn.MaxPool2d(kernel_size=2, stride=2)(cb3)\n",
    "print(\"cb3_ shape: \", cb3_.shape)\n",
    "cb4 = contracting_block4(cb3_)\n",
    "print(\"cb4  shape: \", cb4.shape)\n",
    "cb4_ = nn.MaxPool2d(kernel_size=2, stride=2)(cb4)\n",
    "print(\"cb4_ shape: \", cb4_.shape)\n",
    "cb5 = contracting_block5(cb4_)\n",
    "print(\"cb5  shape: \", cb5.shape)\n",
    "\n",
    "### Expanding network\n",
    "print(\"---------------- Expanding network ----------------\")\n",
    "expanding_block5 = ExpandingBlock(hidden_size * 16, hidden_size * 8)\n",
    "expanding_block4 = ExpandingBlock(hidden_size * 8,  hidden_size * 4)\n",
    "expanding_block3 = ExpandingBlock(hidden_size * 4,  hidden_size * 2)\n",
    "expanding_block2 = ExpandingBlock(hidden_size * 2,  hidden_size * 1)\n",
    "\n",
    "eb5 = UpsamplingBlock(hidden_size*16, hidden_size*8)(cb5)\n",
    "print(\"eb5  shape: \", eb5.shape) \n",
    "eb4 = expanding_block5(eb5, cb4)\n",
    "print(\"eb4  shape: \", eb4.shape) \n",
    "eb4_ = UpsamplingBlock(hidden_size*8, hidden_size*4)(eb4)\n",
    "print(\"eb4_ shape: \", eb4_.shape) \n",
    "eb3 = expanding_block4(eb4_, cb3)\n",
    "print(\"eb3  shape: \", eb3.shape)\n",
    "eb3_ = UpsamplingBlock(hidden_size*4, hidden_size*2)(eb3)\n",
    "print(\"eb3_ shape: \", eb3_.shape) \n",
    "eb2 = expanding_block3(eb3_, cb2)\n",
    "print(\"eb2 shape: \", eb2.shape)\n",
    "eb2_ = UpsamplingBlock(hidden_size*2, hidden_size*1)(eb2)\n",
    "print(\"eb2_ shape: \", eb2_.shape) \n",
    "eb1 = expanding_block2(eb2_, cb1)\n",
    "print(\"eb1 shape: \", eb1.shape)\n",
    "eb0 = nn.Conv2d(hidden_size,1, kernel_size=1)(eb1)\n",
    "print(\"eb0 shape: \", eb0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(10, 1, 512, 512)\n",
    "unet = UNet(1,1,64)\n",
    "u_sample = unet(sample)\n",
    "print(f\"Input shape is {sample.shape} | Output shape is {u_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 200\n",
    "input_dim = 1\n",
    "label_dim = 1\n",
    "display_step = 100\n",
    "hidden_size = 64\n",
    "batch_size = 4\n",
    "lr = 0.0002\n",
    "initial_shape = 512\n",
    "target_shape = 324\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "volumes = torch.Tensor(io.imread('../datasets/unet/train-volume.tif'))[:, None, :, :] / 255\n",
    "labels = torch.Tensor(io.imread('../datasets/unet/train-labels.tif', plugin=\"tifffile\"))[:, None, :, :] / 255\n",
    "labels = crop(labels, (target_shape, target_shape))\n",
    "dataset = torch.utils.data.TensorDataset(volumes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "unet = UNet(input_dim, label_dim, hidden_size).to(device)\n",
    "unet_opt = torch.optim.Adam(unet.parameters(), lr=lr)\n",
    "cur_step = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for real, labels in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ### Update U-Net ###\n",
    "        unet_opt.zero_grad()\n",
    "        pred = unet(real)\n",
    "        unet_loss = criterion(pred, labels)\n",
    "        unet_loss.backward()\n",
    "        unet_opt.step()\n",
    "\n",
    "        if cur_step % display_step == 0:\n",
    "            print(f\"Epoch {epoch}: Step {cur_step}: U-Net loss: {unet_loss.item()}\")\n",
    "            show_img_batch(crop(real, torch.Size([target_shape, target_shape])), \n",
    "                           size=(input_dim, target_shape, target_shape))\n",
    "            show_img_batch(labels, size=(label_dim, target_shape, target_shape))\n",
    "            show_img_batch(torch.sigmoid(pred), size=(label_dim, target_shape, target_shape))\n",
    "        cur_step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchpy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
